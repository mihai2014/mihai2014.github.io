
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- CSS only -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
  <!--<link href="../../src/bootstrap-4.3.1-dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">-->

  <!-- JavaScript Bundle with Popper -->
  <!--<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>-->

  <!--Google Code Prettify-->
  <!--https://w3bits.com/google-code-prettify/-->
  <link rel="stylesheet" href="../../src/google-code-prettify/prettify.css" />

<!-- blocktags -->

  <meta name="author" content="Mihai Corciu">
  <meta name="description" content="Data Science with Python" />
  <meta name="keywords" content="pytorch, neural networks definition">

  <title>nn defs in pytorch</title>

  <style>
    .cell{
      border: 1px solid black;	    
    }
    .center-text{
      text-align: center;
    }
    .center-h{
      margin: auto;    
      display: block;
      width: 90%;
    }
    .center-v{
      display: flex;
      justify-content: center;
      /*height: 800px;*/	    
    }	    
    .label{
      display: inline;	    
      /*background-color: cyan;*/
      color: blue;
      font-size: 1.5em;
      border: 1px solid cyan;
    }
    .example{
      font-size: 1.1em;
      margin-left:10px;
    }
    
  </style>
<!-- endblocktags -->  
</head>

<body>

<!-- blockcontent -->
<div class="container">

  <h1 class="center-text"><b>Neural network definitions in pytorch</b></h1>


  <br><br>
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit network definition</p>
      <pre class="prettyprint">
      <code>
# Sum  = [[x1 x2 ... xn],] * [[w1 ...],] + [[b1 b2 ... bn]]
#         ...                 [w2 ...],
#                             ...
#                             [wn ...]
# 
# Sum =        x         *        w       +       b 

out = torch.mm(x,w) + b
      </code>
      </pre>
    </div>
    <div class="col-md-6 cell">
      <p class="label">nn.Linear network definition</p>
        <pre class="prettyprint">
        <code>
out = torch.mm(x,w.T) + b[0]
        </code>
        </pre>      
    </div>
  </div>

  <br><br>

   <h2>2 inputs, 1 output</h2>

   <!-- images --> 
  <div class="row">  
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_o1_sigmoid_01a.png" alt="nn">	
    </div>
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_o1_sigmoid_01.png" alt="nn">
    </div>
  </div>

  <!-- code -->
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit</p> 
      <span class="example"><a href="/book/ml/Pytorch/1a-2inputs-1output.html" target="_blank">see example</a></span>
        <pre class="prettyprint">
        <code>
# Define the size of each layer in our network
n_input = 2    # Number of input units, must match number of input features
n_hidden = 1   # Number of hidden units 
n_output = 1   # Number of output units

# Weights for inputs to hidden layer
w = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)

# and bias terms for hidden and output layers
b = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)

out = torch.nn.Sigmoid()(torch.mm(x,w)+(b))
        </code>	  
	</pre>
    </div>
    <div class="col-md-6 cell">
      <p class="label">Class+Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/1b-2inputs-1output.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class NN:
    
    def __init__(self, n_input, n_hidden, n_output):

        # Weights for inputs to hidden layer
        self.w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
        # and bias terms for hidden and output layers
        self.b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
        self.activation = torch.nn.Sigmoid()
        
    def forward(self,x):
        o = self.activation(torch.mm(x,self.w1)+(self.b1))
        return o
    
net = NN(2,1,1)
out = net.forward(x)
      </code>
      </pre>
    </div>
  </div>

  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Class+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/1c-2inputs-1output.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(2,1)
        self.activation = nn.Sigmoid()

    def forward(self,x):
        o = self.linear(x)
        o = self.activation(o)
        return o

net = Network()
out = net(x)
#or 
#out = net.forward(x)
      </code>
      </pre>
    </div>
    <div class="col-md-6 cell">
      <p class="label">Sequential+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/1d-2inputs-1output.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
#                   nn.Linear(input,neurons)      

net = nn.Sequential(nn.Linear(2, 1),
                    nn.Sigmoid(),
                   )

out = net(x)
#or 
#out = net.forward(x)
      </code>
      </pre>
    </div>
  </div>
  <!-- end code -->



   <h2>2 inputs, 2 output</h2>

   <!-- images -->
   <div class="row">
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_o2_sigmoid_01a.png" alt="nn">
    </div>
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_o2_sigmoid_01.png" alt="nn">
    </div>
  </div>

  <!-- code -->
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/2a-2inputs-2outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
# Define the size of each layer in our network
n_input = 2    # Number of input units, must match number of input features
n_hidden = 2   # Number of hidden units 
n_output = 2   # Number of output units

# Weights for inputs to hidden layer
w = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)

# and bias terms for hidden and output layers
b = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)

out = torch.nn.Sigmoid()(torch.mm(x,w)+(b))
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Class+Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/2b-2inputs-2outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class NN:
    
    def __init__(self, n_input, n_hidden, n_output):

        # Weights for inputs to hidden layer
        self.w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
        # and bias terms for hidden and output layers
        self.b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
        self.activation = torch.nn.Sigmoid()
        
    def forward(self,x):
        o = self.activation(torch.mm(x,self.w1)+(self.b1))
        return o
    
net = NN(2,2,2)
out = net.forward(x) 
      </code>
      </pre>      
    </div>
  </div>


  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Class+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/2c-2inputs-2outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(2,2)
        self.activation = nn.Sigmoid()
        
    def forward(self,x):
        o = self.linear(x)
        o = self.activation(o)
        return o

net = Network()
out = net(x) 
#or
#out = net.forward(x)
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Sequential+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/2d-2inputs-2outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
net = torch.nn.Sequential(
  torch.nn.Linear(2,2),
  torch.nn.Sigmoid()
)
out = net(x)
      </code>
      </pre>      
    </div>
  </div>
  <!-- end code -->


 <h2>2 inputs, 3 output</h2>

   <!-- images -->
   <div class="row">
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_o3_sigmoid_01a.png" alt="nn">
    </div>
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_o3_sigmoid_01.png" alt="nn">
    </div>
  </div>

  <!-- code -->
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/3a-2inputs-3outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
# Define the size of each layer in our network
n_input = 2    # Number of input units, must match number of input features
n_hidden = 3   # Number of hidden units 
n_output = 3   # Number of output units

# Weights for inputs to hidden layer
w = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)

# and bias terms for hidden and output layers
b = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)

out = torch.nn.Sigmoid()(torch.mm(x,w)+(b))
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Class+Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/3b-2inputs-3outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class NN:
    
    def __init__(self, n_input, n_hidden, n_output):

        # Weights for inputs to hidden layer
        self.w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
        # and bias terms for hidden and output layers
        self.b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
        self.activation = torch.nn.Sigmoid()
        
    def forward(self,x):
        o = self.activation(torch.mm(x,self.w1)+(self.b1))
        return o
    
net = NN(2,3,3)
print(net.forward(x)) 
      </code>
      </pre>      
    </div>
  </div>


  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Class+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/3c-2inputs-3outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(2,3)
        self.activation = nn.Sigmoid()
        
    def forward(self,x):
        o = self.linear(x)
        o = self.activation(o)
        return o

net = Network()
net.forward(x)  
      </code>
      </pre>      
    </div>

    <div class="col-md-6 cell">
      <p class="label">Sequential+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/3d-2inputs-3outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
net = torch.nn.Sequential(
  torch.nn.Linear(2,3),
  torch.nn.Sigmoid()
  );

out = net(x)
      </code>
      </pre>      
    </div>
  </div>
  <!-- end code -->


 <h2>3 inputs, 2 outputs</h2>

   <!-- images -->
   <div class="row">
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i3_o2_sigmoid_01a.png" alt="nn">
    </div>
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i3_o2_sigmoid_01.png" alt="nn">
    </div>
  </div>

  <!-- code -->
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/4a-3inputs-2output.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
# Define the size of each layer in our network
n_input = 3    # Number of input units, must match number of input features
n_hidden = 2   # Number of hidden units 
n_output = 2   # Number of output units

# Weights for inputs to hidden layer
w = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)

# and bias terms for hidden and output layers
b = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)

out = torch.nn.Sigmoid()(torch.mm(x,w)+(b))
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Class+Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/4b-3inputs-2outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class NN:
    
    def __init__(self, n_input, n_hidden, n_output):

        # Weights for inputs to hidden layer
        self.w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
        # and bias terms for hidden and output layers
        self.b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
        self.activation = torch.nn.Sigmoid()
        
    def forward(self,x):
        o = self.activation(torch.mm(x,self.w1)+(self.b1))
        return o
    
net = NN(3,2,2)
out = net.forward(x) 
      </code>
      </pre>      
    </div>
  </div>


  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Class+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/4c-3inputs-2-outpus.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(3,2)
        self.activation = nn.Sigmoid()
        
    def forward(self,x):
        o = self.linear(x)
        o = self.activation(o)
        return o

net = Network()
out = net(x)
#or
#out = net.forward(x)  
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Sequential+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/4d-3inputs-2outputs.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
net = torch.nn.Sequential(
  torch.nn.Linear(3,2),
  torch.nn.Sigmoid()
  );

out = net(x)
      </code>
      </pre>      
    </div>
  </div>
  <!-- end code -->


<h2>1 Hidden Layer : 2 neuron, 1 Output Layer</h2>

   <!-- images -->
   <div class="row">
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_H1_n2_o1_sigmoid_01a.png" alt="nn">
    </div>
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_H1_n2_o1_sigmoid_01.png" alt="nn">
    </div>
  </div>

  <!-- code -->
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/5a-2in-2-1-n-1out.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
# Define the size of each layer in our network
n_input = 2    # Number of input units, must match number of input features
n_hidden = 2   # Number of hidden units 
n_output = 1   # Number of output units

# Weights for inputs to hidden layer
w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
# Weights for hidden layer to output layer
w2 = torch.randn(n_hidden, n_output, dtype=torch.double, requires_grad=True)

# and bias terms for hidden and output layers
b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
b2 = torch.randn(1, n_output, dtype=torch.double, requires_grad=True)

h = activation(torch.mm(x,w1) + b1)
output = activation(torch.mm(h,w2) + b2)
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Class+Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/5b-2in-2-1-n-1out.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class NN():    
    def __init__(self, n_input, n_hidden, n_output):

        # Weights for inputs to hidden layer
        self.w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
        # Weights for hidden layer to output layer
        self.w2 = torch.randn(n_hidden, n_output, dtype=torch.double, requires_grad=True)

        # and bias terms for hidden and output layers
        self.b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
        self.b2 = torch.randn(1, n_output, dtype=torch.double, requires_grad=True)  
        
        self.activation = torch.nn.Sigmoid()
        
    def forward(self,x):        
        o = activation(torch.mm(x,self.w1) + self.b1)
        o = activation(torch.mm(o,self.w2) + self.b2)            
        return o
        
net = NN(2,2,1)
out = net.forward(x)         
      </code>
      </pre>      
    </div>
  </div>


  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Class+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/5c-2in-2-1-n-1out.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(2,2)
        self.linear2 = nn.Linear(2,1)
        
    def forward(self,x):
        o = self.linear1(x)
        o = torch.nn.Sigmoid()(o)
        o = self.linear2(o)
        o = torch.nn.Sigmoid()(o)
        return o

net = Network()
out = net.forward(x)  
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Sequential+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/5d-2in-2-1-n-1out.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
net = torch.nn.Sequential(
  torch.nn.Linear(2,2),
  torch.nn.Sigmoid(),
  torch.nn.Linear(2,1),
  torch.nn.Sigmoid()
  );
out = net(x)  
      </code>
      </pre>      
    </div>
  </div>
  <!-- end code -->


  <h2>1 Hidden Layer : 3 neuron, 1 Output Layer</h2>

   <!-- images -->
   <div class="row">
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_H1_n3_o1_sigmoid_01a.png" alt="nn">
    </div>
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i2_H1_n3_o1_sigmoid_01.png" alt="nn">
    </div>
  </div>

  <!-- code -->
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/6a-3in-3-1-n-1out.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
# Define the size of each layer in our network
n_input = 2    # Number of input units, must match number of input features
n_hidden = 3   # Number of hidden units 
n_output = 1   # Number of output units

# Weights for inputs to hidden layer
w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
# Weights for hidden layer to output layer
w2 = torch.randn(n_hidden, n_output, dtype=torch.double, requires_grad=True)

# and bias terms for hidden and output layers
b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
b2 = torch.randn(1, n_output, dtype=torch.double, requires_grad=True)

h = activation(torch.mm(x,w1) + b1)
output = activation(torch.mm(h,w2) + b2)
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Class+Explicit</p>
      <span class="example"><a href="/book/ml/Pytorch/6b-3in-3-1-n-1out.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class NN():    
    def __init__(self, n_input, n_hidden, n_output):

        # Weights for inputs to hidden layer
        self.w1 = torch.randn(n_input, n_hidden, dtype=torch.double, requires_grad=True)
        # Weights for hidden layer to output layer
        self.w2 = torch.randn(n_hidden, n_output, dtype=torch.double, requires_grad=True)

        # and bias terms for hidden and output layers
        self.b1 = torch.randn(1, n_hidden, dtype=torch.double, requires_grad=True)
        self.b2 = torch.randn(1, n_output, dtype=torch.double, requires_grad=True)  
        
        self.activation = torch.nn.Sigmoid()
        
    def forward(self,x):        
        o = activation(torch.mm(x,self.w1) + self.b1)
        o = activation(torch.mm(o,self.w2) + self.b2)        
        return o

net = NN(2,3,1)
out = net.forward(x)        
      </code>
      </pre>      
    </div>
  </div>


  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Class+Linear</p>
      <span class="example"><a href="/book/ml/Pytorch/6c-3in-3-1-n-1out.html" target="_blank">see example</a></span>
      <pre class="prettyprint">
      <code>
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(2,3)
        self.linear2 = nn.Linear(3,1)
        
    def forward(self,x):
        o = self.linear1(x)
        o = torch.nn.Sigmoid()(o)
        o = self.linear2(o)
        o = torch.nn.Sigmoid()(o)
        return o

net = Network()
out = net.forward(x)
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Sequential+Linear</p>
      <!--<span class="example"><a href="/book/ml/Pytorch/6d-3in-3-1-n-1out.html" target="_blank">see example</a></span>-->
      <pre class="prettyprint">
      <code>
net = torch.nn.Sequential(
  torch.nn.Linear(2,3),
  torch.nn.Sigmoid()
  torch.nn.Linear(3,1),
  torch.nn.Sigmoid()
);
</code>
      </pre>      
    </div>
  </div>
  <!-- end code -->


  <h2>2 Hidden Layers : 4 and 6 Neurons, and 1 Output Neurons</h2>

   <!-- images -->
   <div class="row">
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i1_H1_n4_H2_n6_o1_sigmoid_01a.png" alt="nn">
    </div>
    <div class="col cell center-v">
      <img class="center-h" src="nn_img/Python_Pytorch_nn_Sequential_i1_H1_n4_H2_n6_o1_sigmoid_01.png" alt="nn">
    </div>
  </div>

  <!-- code -->
  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Explicit</p>
      <!--<span class="example"><a href="#" target="_blank">see example</a></span>-->
      <pre class="prettyprint">
      <code>
# Define the size of each network layer
n_input   = 1   # Number of input units, must match number of input features
n_hidden1 = 4   # Number of hidden units 
n_hidden2 = 6   # Number of hidden units 
n_output  = 1   # Number of output units

w1 = torch.randn(n_input,   n_hidden1, dtype=torch.float, requires_grad=True)
w2 = torch.randn(n_hidden1, n_hidden2, dtype=torch.float, requires_grad=True)
w3 = torch.randn(n_hidden3,  n_output, dtype=torch.float, requires_grad=True)

b1 = torch.randn(1, n_hidden1, dtype=torch.float, requires_grad=True)
b2 = torch.randn(1, n_hidden2, dtype=torch.float, requires_grad=True)
b3 = torch.randn(1,  n_output, dtype=torch.float, requires_grad=True)

o = torch.nn.Sigmoid()(torch.mm(x,w1)+(b1))
o = torch.nn.Sigmoid()(torch.mm(o,w2)+(b2))
o = torch.nn.Sigmoid()(torch.mm(o,w3)+(b3))

out = o
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Class+Explicit</p>
      <!--<span class="example"><a href="#" target="_blank">see example</a></span>-->
      <pre class="prettyprint">
      <code>
class NN:
    
    def __init__(self, n_input, n_hidden1, n_hidden2, n_hidden3, n_output):

        self.w1 = torch.randn(n_input,   n_hidden1, dtype=torch.float, requires_grad=True)
        self.w2 = torch.randn(n_hidden1, n_hidden2, dtype=torch.float, requires_grad=True)
        self.w3 = torch.randn(n_hidden2, n_output,  dtype=torch.float, requires_grad=True)
        

        self.b1 = torch.randn(1, n_hidden1, dtype=torch.float, requires_grad=True)
        self.b2 = torch.randn(1, n_hidden2, dtype=torch.float, requires_grad=True)
        self.b3 = torch.randn(1, n_output,  dtype=torch.float, requires_grad=True)
        
        
    def forward(self,x):
        o = torch.nn.Sigmoid()(torch.mm(x,w1)+(b1))
        o = torch.nn.Sigmoid()(torch.mm(o,w2)+(b2))
        o = torch.nn.Sigmoid()(torch.mm(o,w3)+(b3))
        
        return o
    
net = NN(1,4,3,2,1)

out = net.forward(x)
      </code>
      </pre>      
    </div>
  </div>


  <div class="row">
    <div class="col-md-6 cell">
      <p class="label">Class+Linear</p>
      <!--<span class="example"><a href="#" target="_blank">see example</a></span>-->
      <pre class="prettyprint">
      <code>
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(1,4)
        self.linear2 = nn.Linear(4,6)
        self.linear3 = nn.Linear(6,1)

    def forward(self,x):
        o = torch.nn.Sigmoid()(self.linear1(x))
        o = torch.nn.Sigmoid()(self.linear2(o))
        o = torch.nn.Sigmoid()(self.linear3(o))
        return o

net = Network()
out = net(x)
      </code>
      </pre>      
    </div>
    <div class="col-md-6 cell">
      <p class="label">Sequential+Linear</p>
      <!--<span class="example"><a href="#" target="_blank">see example</a></span>-->
      <pre class="prettyprint">
      <code>
net = torch.nn.Sequential(
  torch.nn.Linear(1,4),
  torch.nn.Sigmoid(),
  torch.nn.Linear(4,6),
  torch.nn.Sigmoid(),
  torch.nn.Linear(6,1),
  torch.nn.Sigmoid()
);
      </code>
      </pre>      
    </div>
  </div>
  <!-- end code -->

<br>
<p>Reference:</p>
<p>http://www.sharetechnote.com/html/Python_PyTorch_nn_Sequential_01.html</p>

</div>

<!-- endblockcontent -->

<script src="../../src/google-code-prettify/prettify.js"></script>
<script>
  window.onload = (function(){ prettyPrint(); });
</script>


</body>
</html>

